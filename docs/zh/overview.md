# 实验概述
🎬 *你的任务，如果你选择接受的话*

## 你的角色和任务

你是 **ACME 公司的高级 AI 工程师**，被分配评估和实施一个能够高效服务多个大型语言模型（LLM）的 AI 推理系统。

ACME 需要升级其客户支持基础设施，以应对不断增长的需求，同时保持响应质量。你的经理解释道：

> "我们需要一个灵活的 AI 推理平台，能够服务多个模型，与外部工具集成，并满足我们的企业级需求。"

**你的任务**：评估 vLLM 作为 ACME AI 推理服务的基础，展示其模型服务、工具调用和智能体工作流的能力。

**目标**：证明 vLLM 可以提供高性能的 LLM 推理，具备结构化输出、工具调用和 MCP 集成等高级功能。

!!! info "关于 vLLM Playground"
    在整个实验过程中，你将使用 **[vLLM Playground](https://github.com/micytao/vllm-playground)** —— 一个让 vLLM 变得易于使用和可视化的现代 Web 界面。它处理容器管理、配置，并提供直观的聊天界面来探索 vLLM 的功能。

## 任务成功标准

完成本实验后，你将获得实用的 AI 推理技能，以解决 ACME 的客户支持挑战：

| 技能 | 业务成果 |
|------|----------|
| 使用 Podman 容器部署和管理 vLLM 服务器 | 建立可靠的模型服务基础设施 |
| 通过现代聊天界面与 LLM 交互 | 展示实时客户交互能力 |
| 配置结构化输出以获得一致的 AI 响应 | 确保下游系统获得可预测、可解析的数据 |
| 实现工具调用以实现动态功能 | 使 AI 能够执行操作和检索信息 |
| 设置 MCP 服务器以实现智能体能力 | 通过外部工具访问和人工审批扩展 AI |
| 运行性能基准测试以验证吞吐量 | 证明系统可以处理生产工作负载 |

**技术成果**：你将获得直接应用于 ACME AI 基础设施需求的 vLLM 实践经验。

**业务收益**：一个经过验证的 AI 推理平台，可实现具有企业级可靠性的智能客户支持。

## 目标受众

本实验专为以下人员设计：

- 🧑‍💻 **AI 工程师** 构建推理基础设施
- 👨‍💻 **开发人员** 将 LLM 集成到应用程序中
- 🏗️ **平台工程师** 评估 AI 服务解决方案
- 📐 **架构师** 设计企业级 AI 系统

## 成功所需条件

你应该具备：

- ✅ 基本的 Linux 经验 — 你之前使用过终端
- ✅ 了解容器 — 你知道如何运行 Podman/Docker 容器
- ✅ 基本的 AI/ML 概念 — 你了解 LLM 和推理的含义
- ✅ 一台支持 GPU 的机器（或者对 CPU 模式有耐心）

## ACME 公司的 AI 挑战

**情况**：ACME 公司需要构建一个 AI 驱动的客户支持系统，能够高效处理各种客户咨询。

**项目时间线**：评估 vLLM 并展示其满足 ACME 企业级 AI 需求的能力。

### 当前挑战

| 挑战 | 影响 |
|------|------|
| **AI 响应不一致** | 不同模型产生不同的输出格式 → 与现有系统集成困难 |
| **工具集成有限** | 当前 AI 解决方案无法执行操作或访问外部数据 → 降低自动化潜力 |
| **手动模型管理** | 部署和更新模型需要大量工作 → 减慢迭代周期 |
| **可扩展性问题** | 不确定当前方法是否能处理生产流量 → 客户体验风险 |

**机会**：vLLM 提供了一个统一的模型服务平台，具有可以解决这些挑战的高级功能，你被选中来评估其对 ACME 用例的可行性。

## 你的成功愿景

如果 vLLM 证明对 ACME 的用例有效，以下是潜在的改进：

### 即时改进（短期）

- ⚡ **更快的模型部署**：通过容器在几分钟内部署新模型 → 加速实验和迭代
- 📋 **一致的 AI 输出**：结构化输出确保可预测的响应格式 → 简化与下游系统的集成

### 战略收益（长期）

- 🤖 **智能体能力**：MCP 集成使 AI 能够使用外部工具 → 扩展自动化可能性
- 👤 **人工审批**：通过手动审批安全执行工具 → 保持对 AI 操作的控制
- 📊 **性能可见性**：内置基准测试验证吞吐量 → 自信的容量规划

**成功指标**：一个可演示的 AI 推理平台，能够服务多个模型，具有工具调用、结构化输出和智能体能力，适合 ACME 的客户支持需求。

## 常见问题

??? question "我们可以针对不同用例使用不同的模型吗？"
    是的！vLLM 支持各种模型，包括 Llama、Mistral 和 Qwen，并提供模型特定的优化。

??? question "如何控制 AI 输出以适应我们的系统？"
    模块 2 介绍了使用 JSON Schema、Regex 和 Grammar 来约束响应的结构化输出。

??? question "工具调用如何在客户支持场景中工作？"
    模块 3 演示了定义自定义工具，AI 可以调用这些工具来检索客户数据或执行支持操作。

??? question "我们可以扩展 AI 以访问我们的内部系统吗？"
    模块 4 展示了 MCP 集成，用于将 AI 连接到外部工具，并提供人工审批。

??? question "我们如何验证系统能够处理生产工作负载？"
    模块 5 介绍了使用 GuideLLM 进行性能基准测试，以测量吞吐量、延迟和优化服务器配置。

---

**准备好开始了吗？** 继续访问 [开始之前](details.md) 查看模块分解和时间安排。
